{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VI - Tensorboard Visualization\n",
    "This notebook will show how to create an SSH tunnel from the machine running the Notebook to the compute node of a task that is running or has run a task that has generated [Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) summary compatible output.\n",
    "\n",
    "**NOTE:** This notebook cannot be run on Azure notebooks due to restrictions. Please run this notebook locally. If you are running this notebook on Windows, please ensure you have `ssh.exe` in your `%PATH%`. You can download OpenSSH binaries for Windows [here](https://github.com/PowerShell/Win32-OpenSSH/releases).\n",
    "\n",
    "* [Setup](#section1)\n",
    "* [Configure job](#section2)\n",
    "* [Submit job](#section3)\n",
    "* [Delete job](#section4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple alias for Batch Shipyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%alias shipyard SHIPYARD_CONFIGDIR=config python $HOME/batch-shipyard/shipyard.py %l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shipyard.py, version 2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "shipyard --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some variables stored in the Setup notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as infile:\n",
    "        return json.load(infile)\n",
    "    \n",
    "account_info = read_json('account_information.json')\n",
    "\n",
    "IMAGE_NAME = account_info['IMAGE_NAME']\n",
    "STORAGE_ALIAS = account_info['STORAGE_ALIAS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Configure job\n",
    "The following will be similar to the [Single GPU Training](02_Single_GPU_Training.ipynb) notebook from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `jobs` configuration, we will add `--logdir=tensorboard_logs` as a parameter to generate the Tensorboard summary log data during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TASK_ID = 'run_cifar10' # This should be changed per task\n",
    "\n",
    "JOB_ID = 'cntk-train-tensorboard-job'\n",
    "\n",
    "COMMAND = 'bash -c \"source /cntk/activate-cntk; python -u ConvNet_CIFAR10.py --datadir $AZ_BATCH_NODE_SHARED_DIR/data --tensorboard_logdir tensorboard_logs\"'\n",
    "\n",
    "jobs = {\n",
    "    \"job_specifications\": [\n",
    "        {\n",
    "            \"id\": JOB_ID,\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"id\": TASK_ID,\n",
    "                    \"image\": IMAGE_NAME,\n",
    "                    \"remove_container_after_exit\": True,\n",
    "                    \"command\": COMMAND,\n",
    "                    \"gpu\": True,\n",
    "                    \"resource_files\": [\n",
    "                        {\n",
    "                            \"file_path\": \"ConvNet_CIFAR10.py\",\n",
    "                            \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/ConvNet_CIFAR10.py\",\n",
    "                            \"file_mode\":'0777'\n",
    "                        }\n",
    "                    ],\n",
    "                    \"output_data\": {\n",
    "                        \"azure_storage\": [\n",
    "                            {\n",
    "                                \"storage_account_settings\": STORAGE_ALIAS,\n",
    "                                \"container\": \"output\",\n",
    "                                \"source\": \"$AZ_BATCH_TASK_WORKING_DIR/Models\"\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write the jobs configuration to the `jobs.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"job_specifications\": [\n",
      "        {\n",
      "            \"id\": \"cntk-train-tensorboard-job\", \n",
      "            \"tasks\": [\n",
      "                {\n",
      "                    \"command\": \"bash -c \\\"source /cntk/activate-cntk; python -u ConvNet_CIFAR10.py --datadir $AZ_BATCH_NODE_SHARED_DIR/data --tensorboard_logdir tensorboard_logs\\\"\", \n",
      "                    \"gpu\": true, \n",
      "                    \"id\": \"run_cifar10\", \n",
      "                    \"image\": \"microsoft/cntk:2.0-gpu-python3.5-cuda8.0-cudnn5.1\", \n",
      "                    \"output_data\": {\n",
      "                        \"azure_storage\": [\n",
      "                            {\n",
      "                                \"container\": \"output\", \n",
      "                                \"source\": \"$AZ_BATCH_TASK_WORKING_DIR/Models\", \n",
      "                                \"storage_account_settings\": \"mystorageaccount\"\n",
      "                            }\n",
      "                        ]\n",
      "                    }, \n",
      "                    \"remove_container_after_exit\": true, \n",
      "                    \"resource_files\": [\n",
      "                        {\n",
      "                            \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/ConvNet_CIFAR10.py\", \n",
      "                            \"file_mode\": \"0777\", \n",
      "                            \"file_path\": \"ConvNet_CIFAR10.py\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def write_json_to_file(json_dict, filename):\n",
    "    \"\"\" Simple function to write JSON dictionaries to files\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(json_dict, outfile)\n",
    "\n",
    "write_json_to_file(jobs, os.path.join('config', 'jobs.json'))\n",
    "print(json.dumps(jobs, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job\n",
    "Check that everything is ok with our pool before we submit our jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:45:45,080 DEBUG - listing nodes for pool gpupool\n",
      "2017-07-12 14:45:45,403 INFO - node_id=tvm-1392786932_1-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.6 vm_size=standard_nc6 dedicated=True total_tasks_run=2 running_tasks_count=0 total_tasks_succeeded=2]\n",
      "2017-07-12 14:45:45,403 INFO - node_id=tvm-1392786932_2-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.5 vm_size=standard_nc6 dedicated=True total_tasks_run=3 running_tasks_count=0 total_tasks_succeeded=3]\n",
      "2017-07-12 14:45:45,403 INFO - node_id=tvm-1392786932_3-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.4 vm_size=standard_nc6 dedicated=True total_tasks_run=5 running_tasks_count=0 total_tasks_succeeded=5]\n"
     ]
    }
   ],
   "source": [
    "shipyard pool listnodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed everything is working we can execute our job using the command below. Note that we'll not be using the `--tail` option so that the command completes and we can tunnel to Tensorboard concurrently as the task is executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:45:49,216 INFO - Adding job cntk-train-tensorboard-job to pool gpupool\n",
      "2017-07-12 14:45:49,784 INFO - uploading file /tmp/tmp5o3cih as u'shipyardtaskrf-cntk-train-tensorboard-job/run_cifar10.shipyard.envlist'\n",
      "2017-07-12 14:45:50,016 DEBUG - submitting 1 tasks (0 -> 0) to job cntk-train-tensorboard-job\n",
      "2017-07-12 14:45:50,308 INFO - submitted all 1 tasks to job cntk-train-tensorboard-job\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Batch Shipyard command to instantiate a Tensorboard instance and create an SSH tunnel. The following cell should not return immediately if it is working. Browse to the Tensorboard URL output by the command (which will not be output in the notebook since it is a blocking call), which is http://localhost:6006/\n",
    "\n",
    "**Notes:**\n",
    "1. The Tensorboard instance may take some time to start since this pool does not have the TensorFlow Docker image pre-loaded.\n",
    "2. You will need to manually interrupt the kernel once you are done with your Tensorboard visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:45:57,169 INFO - job_id=cntk-train-tensorboard-job task_id=run_cifar10 [state=TaskState.running max_retries=0 retention_time=10675199 days, 2:48:05.477581 pool_id=gpupool node_id=tvm-1392786932_3-20170712t132611z start_time=2017-07-12 14:45:50.862843+00:00 end_time=None duration=n/a exit_code=None]\r\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs listtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:46:01,347 DEBUG - waiting for task run_cifar10 in job cntk-train-tensorboard-job to reach a valid state\n",
      "2017-07-12 14:46:01,557 DEBUG - using auto-detected logdir: tensorboard_logs\n",
      "2017-07-12 14:46:01,557 DEBUG - using logpath: /mnt/batch/tasks/workitems/cntk-train-tensorboard-job/job-1/run_cifar10/wd/tensorboard_logs\n",
      "2017-07-12 14:46:01,557 WARNING - no pre-loaded tensorflow Docker image detected on pool, using: gcr.io/tensorflow/tensorflow:1.1.0\n",
      "2017-07-12 14:46:01,749 INFO - \n",
      "\n",
      ">> Please connect to Tensorboard at http://localhost:6006/\n",
      "\n",
      ">> Note that Tensorboard may take a while to start if the Docker is\n",
      ">> not present. Please keep retrying the URL every few seconds.\n",
      "\n",
      ">> Terminate your session with CTRL+C\n",
      "\n",
      ">> If you cannot terminate your session cleanly, run:\n",
      "     shipyard pool ssh --nodeid tvm-1392786932_3-20170712t132611z sudo docker kill e32f11ac\n",
      "\n",
      "Warning: Permanently added '[52.168.26.170]:50000' (ECDSA) to the list of known hosts.\n",
      "Warning: Permanently added '[52.168.26.170]:50000' (ECDSA) to the list of known hosts.\n",
      "Connection to 52.168.26.170 closed.\n",
      "2017-07-12 14:46:08,978 DEBUG - attempting clean up of Tensorboard instance and SSH tunnel\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shipyard misc tensorboard --jobid $JOB_ID --taskid $TASK_ID -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the job use the command below. Just be aware that this will get rid of all the files created by the job and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:48:52,609 INFO - Deleting job: cntk-train-tensorboard-job\n",
      "2017-07-12 14:48:52,609 DEBUG - disabling job cntk-train-tensorboard-job first due to task termination\n",
      "2017-07-12 14:48:53,527 INFO - Terminating task: run_cifar10\n",
      "Warning: Permanently added '[52.168.26.170]:50000' (ECDSA) to the list of known hosts.\n",
      "cntk-train-tensorboard-job-run_cifar10\n",
      "Connection to 52.168.26.170 closed.\n",
      "2017-07-12 14:48:54,976 DEBUG - waiting for task run_cifar10 in job cntk-train-tensorboard-job to terminate\n",
      "2017-07-12 14:48:55,333 DEBUG - waiting for job cntk-train-tensorboard-job to delete\n",
      "2017-07-12 14:49:27,329 INFO - job cntk-train-tensorboard-job does not exist\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs del -y --termtasks --wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 14:50:20,221 INFO - Deleting pool: gpupool\n",
      "2017-07-12 14:50:20,503 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardregistry\n",
      "2017-07-12 14:50:20,803 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardgr\n",
      "2017-07-12 14:50:20,912 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardperf\n",
      "2017-07-12 14:50:20,962 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyarddht\n",
      "2017-07-12 14:50:21,013 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardimages\n",
      "2017-07-12 14:50:21,115 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardtorrentinfo\n",
      "2017-07-12 14:50:21,166 DEBUG - deleting queue: shipyardgr-batch0e43a94eba-gpupool\n",
      "2017-07-12 14:50:21,420 DEBUG - deleting container: shipyardtor-batch0e43a94eba-gpupool\n",
      "2017-07-12 14:50:21,637 DEBUG - deleting container: shipyardrf-batch0e43a94eba-gpupool\n",
      "2017-07-12 14:50:21,684 DEBUG - waiting for pool gpupool to delete\n"
     ]
    }
   ],
   "source": [
    "shipyard pool del -y --wait"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
