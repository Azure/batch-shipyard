{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# I - Setup\n",
    "This notebook will set up everything for the tutorial. This notebook assumes that nothing has been set up previously and will create everything from scratch. The necessary steps are broken up into the following sections:\n",
    "\n",
    "**Note:** By using these notebooks on GPU VMs, you agree to the [NVIDIA Software License](http://www.nvidia.com/content/DriverDownload-March2009/licence.php?lang=us).\n",
    "\n",
    "* [Install tools and dependencies](#section1)\n",
    "* [Azure account login](#section2)\n",
    "* [Setup](#section3)\n",
    "* [Create Azure resources](#section4)\n",
    "* [Batch Shipyard Configuration](#section5)\n",
    "* [Create Azure Batch Pool](#section6)\n",
    "* [View Resources on Azure Portal or Batch Labs](#section7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install tools and dependencies\n",
    "Install Batch Shipyard and Azure CLI 2.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'batch-shipyard'...\n",
      "remote: Counting objects: 4890, done.\u001b[K\n",
      "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
      "remote: Total 4890 (delta 81), reused 90 (delta 40), pack-reused 4745\u001b[K\n",
      "Receiving objects: 100% (4890/4890), 1.94 MiB | 0 bytes/s, done.\n",
      "Resolving deltas: 100% (3415/3415), done.\n",
      "Checking connectivity... done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/Azure/batch-shipyard.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally you would use `install.sh` or `install.cmd` helper scripts to install, but due to the Notebook environment, we will instead install with the `requirements.txt` file directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied (use --upgrade to upgrade): adal==0.4.5 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from -r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-batch==3.0.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from -r batch-shipyard/requirements.txt (line 2))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-keyvault==0.3.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from -r batch-shipyard/requirements.txt (line 3))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-mgmt-batch==4.0.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from -r batch-shipyard/requirements.txt (line 4))\n",
      "Collecting azure-mgmt-compute==1.0.0 (from -r batch-shipyard/requirements.txt (line 5))\n",
      "  Downloading azure_mgmt_compute-1.0.0-py2.py3-none-any.whl (379kB)\n",
      "\u001b[K    100% |################################| 389kB 2.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-network==1.0.0 (from -r batch-shipyard/requirements.txt (line 6))\n",
      "  Downloading azure_mgmt_network-1.0.0-py2.py3-none-any.whl (818kB)\n",
      "\u001b[K    100% |################################| 819kB 1.2MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting azure-mgmt-resource==1.1.0 (from -r batch-shipyard/requirements.txt (line 7))\n",
      "  Downloading azure_mgmt_resource-1.1.0-py2.py3-none-any.whl (301kB)\n",
      "\u001b[K    100% |################################| 307kB 3.1MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting azure-storage==0.34.2 (from -r batch-shipyard/requirements.txt (line 8))\n",
      "  Downloading azure_storage-0.34.2-py2.py3-none-any.whl (187kB)\n",
      "\u001b[K    100% |################################| 194kB 4.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting blobxfer==0.12.1 (from -r batch-shipyard/requirements.txt (line 9))\n",
      "  Downloading blobxfer-0.12.1-py2.py3-none-any.whl (41kB)\n",
      "\u001b[K    100% |################################| 51kB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting click==6.7 (from -r batch-shipyard/requirements.txt (line 10))\n",
      "  Downloading click-6.7-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K    100% |################################| 71kB 5.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting future==0.16.0 (from -r batch-shipyard/requirements.txt (line 11))\n",
      "  Downloading future-0.16.0.tar.gz (824kB)\n",
      "\u001b[K    100% |################################| 829kB 1.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting msrest==0.4.8 (from -r batch-shipyard/requirements.txt (line 12))\n",
      "  Downloading msrest-0.4.8-py2.py3-none-any.whl\n",
      "Collecting msrestazure==0.4.7 (from -r batch-shipyard/requirements.txt (line 13))\n",
      "  Downloading msrestazure-0.4.7-py2.py3-none-any.whl\n",
      "Collecting pathlib2==2.2.1 (from -r batch-shipyard/requirements.txt (line 14))\n",
      "  Downloading pathlib2-2.2.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests==2.14.2 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from -r batch-shipyard/requirements.txt (line 15))\n",
      "Collecting scandir==1.5 (from -r batch-shipyard/requirements.txt (line 16))\n",
      "  Downloading scandir-1.5.tar.gz\n",
      "Requirement already satisfied (use --upgrade to upgrade): python-dateutil>=2.1.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): cryptography>=1.1.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): PyJWT>=1.0.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-common~=1.1.5 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from azure-batch==3.0.0->-r batch-shipyard/requirements.txt (line 2))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-nspkg>=2.0.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from azure-batch==3.0.0->-r batch-shipyard/requirements.txt (line 2))\n",
      "Requirement already satisfied (use --upgrade to upgrade): azure-mgmt-nspkg>=2.0.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from azure-mgmt-batch==4.0.0->-r batch-shipyard/requirements.txt (line 4))\n",
      "Collecting azure-servicemanagement-legacy==0.20.5 (from blobxfer==0.12.1->-r batch-shipyard/requirements.txt (line 9))\n",
      "  Downloading azure_servicemanagement_legacy-0.20.5-py2.py3-none-any.whl (79kB)\n",
      "\u001b[K    100% |################################| 81kB 8.2MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied (use --upgrade to upgrade): certifi>=2017.4.17 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from msrest==0.4.8->-r batch-shipyard/requirements.txt (line 12))\n",
      "Requirement already satisfied (use --upgrade to upgrade): requests-oauthlib>=0.5.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from msrest==0.4.8->-r batch-shipyard/requirements.txt (line 12))\n",
      "Requirement already satisfied (use --upgrade to upgrade): isodate>=0.5.4 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from msrest==0.4.8->-r batch-shipyard/requirements.txt (line 12))\n",
      "Requirement already satisfied (use --upgrade to upgrade): enum34>=1.0.4; python_version < \"3.4\" in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from msrest==0.4.8->-r batch-shipyard/requirements.txt (line 12))\n",
      "Requirement already satisfied (use --upgrade to upgrade): keyring>=5.6 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from msrestazure==0.4.7->-r batch-shipyard/requirements.txt (line 13))\n",
      "Requirement already satisfied (use --upgrade to upgrade): six in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from pathlib2==2.2.1->-r batch-shipyard/requirements.txt (line 14))\n",
      "Requirement already satisfied (use --upgrade to upgrade): idna>=2.0 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): pyasn1>=0.1.8 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): setuptools>=11.3 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages/setuptools-23.0.0-py2.7.egg (from cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): ipaddress in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): cffi>=1.4.1 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Requirement already satisfied (use --upgrade to upgrade): oauthlib>=0.6.2 in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from requests-oauthlib>=0.5.0->msrest==0.4.8->-r batch-shipyard/requirements.txt (line 12))\n",
      "Requirement already satisfied (use --upgrade to upgrade): secretstorage; sys_platform == \"linux2\" or sys_platform == \"linux\" in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from keyring>=5.6->msrestazure==0.4.7->-r batch-shipyard/requirements.txt (line 13))\n",
      "Requirement already satisfied (use --upgrade to upgrade): pycparser in /home/nbcommon/anaconda2_410/lib/python2.7/site-packages (from cffi>=1.4.1->cryptography>=1.1.0->adal==0.4.5->-r batch-shipyard/requirements.txt (line 1))\n",
      "Building wheels for collected packages: future, scandir\n",
      "  Running setup.py bdist_wheel for future ... \u001b[?25l-\b \b\\\b \b|\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/c2/50/7c/0d83b4baac4f63ff7a765bd16390d2ab43c93587fac9d6017a\n",
      "  Running setup.py bdist_wheel for scandir ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/47/af/a2/eb591a17e9709a17d8b53696f6ad89914a05eaf9c091f36e18\n",
      "Successfully built future scandir\n",
      "Installing collected packages: msrest, msrestazure, azure-mgmt-compute, azure-mgmt-network, azure-mgmt-resource, azure-storage, azure-servicemanagement-legacy, blobxfer, click, future, scandir, pathlib2\n",
      "  Found existing installation: msrest 0.4.10\n",
      "    Uninstalling msrest-0.4.10:\n",
      "      Successfully uninstalled msrest-0.4.10\n",
      "  Found existing installation: msrestazure 0.4.9\n",
      "    Uninstalling msrestazure-0.4.9:\n",
      "      Successfully uninstalled msrestazure-0.4.9\n",
      "  Found existing installation: azure-mgmt-compute 1.0.0rc1\n",
      "    Uninstalling azure-mgmt-compute-1.0.0rc1:\n",
      "      Successfully uninstalled azure-mgmt-compute-1.0.0rc1\n",
      "  Found existing installation: azure-mgmt-network 1.0.0rc3\n",
      "    Uninstalling azure-mgmt-network-1.0.0rc3:\n",
      "      Successfully uninstalled azure-mgmt-network-1.0.0rc3\n",
      "  Found existing installation: azure-mgmt-resource 1.1.0rc1\n",
      "    Uninstalling azure-mgmt-resource-1.1.0rc1:\n",
      "      Successfully uninstalled azure-mgmt-resource-1.1.0rc1\n",
      "  Found existing installation: click 6.6\n",
      "    Uninstalling click-6.6:\n",
      "      Successfully uninstalled click-6.6\n",
      "  Found existing installation: future 0.15.2\n",
      "\u001b[33m    DEPRECATION: Uninstalling a distutils installed project (future) has been deprecated and will be removed in a future version. This is due to the fact that uninstalling a distutils project will only partially uninstall the project.\u001b[0m\n",
      "    Uninstalling future-0.15.2:\n",
      "      Successfully uninstalled future-0.15.2\n",
      "  Found existing installation: pathlib2 2.1.0\n",
      "    Uninstalling pathlib2-2.1.0:\n",
      "      Successfully uninstalled pathlib2-2.1.0\n",
      "Successfully installed azure-mgmt-compute-1.0.0 azure-mgmt-network-1.0.0 azure-mgmt-resource-1.1.0 azure-servicemanagement-legacy-0.20.5 azure-storage-0.34.2 blobxfer-0.12.1 click-6.7 future-0.16.0 msrest-0.4.8 msrestazure-0.4.7 pathlib2-2.2.1 scandir-1.5\n",
      "\u001b[33mYou are using pip version 8.1.2, however version 9.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r batch-shipyard/requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Azure CLI 2.0 will also be installed to help us in provisioning Azure Batch and Storage accounts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting azure-cli\n",
      "  Downloading azure_cli-2.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-dls (from azure-cli)\n",
      "  Downloading azure_cli_dls-0.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-network (from azure-cli)\n",
      "  Downloading azure_cli_network-2.0.10-py2.py3-none-any.whl (81kB)\n",
      "\u001b[K    100% |################################| 81kB 3.1MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting azure-cli-resource (from azure-cli)\n",
      "  Downloading azure_cli_resource-2.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-nspkg>=2.0.0 (from azure-cli)\n",
      "  Downloading azure_cli_nspkg-3.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-cli-cdn (from azure-cli)\n",
      "  Downloading azure_cli_cdn-0.0.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-sf (from azure-cli)\n",
      "  Downloading azure_cli_sf-1.0.5-py2.py3-none-any.whl\n",
      "Collecting azure-cli-component (from azure-cli)\n",
      "  Downloading azure_cli_component-2.0.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-appservice (from azure-cli)\n",
      "  Downloading azure_cli_appservice-0.1.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-dla (from azure-cli)\n",
      "  Downloading azure_cli_dla-0.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-interactive (from azure-cli)\n",
      "  Downloading azure_cli_interactive-0.3.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-find (from azure-cli)\n",
      "  Downloading azure_cli_find-0.2.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-iot (from azure-cli)\n",
      "  Downloading azure_cli_iot-0.1.9-py2.py3-none-any.whl\n",
      "Collecting azure-cli-vm (from azure-cli)\n",
      "  Downloading azure_cli_vm-2.0.10-py2.py3-none-any.whl (71kB)\n",
      "\u001b[K    100% |################################| 71kB 3.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting azure-cli-cloud (from azure-cli)\n",
      "  Downloading azure_cli_cloud-2.0.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-configure (from azure-cli)\n",
      "  Downloading azure_cli_configure-2.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-core (from azure-cli)\n",
      "  Downloading azure_cli_core-2.0.11-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |################################| 92kB 4.0MB/s ta 0:00:011\n",
      "\u001b[?25hCollecting azure-cli-batch (from azure-cli)\n",
      "  Downloading azure_cli_batch-3.0.3-py2.py3-none-any.whl\n",
      "Collecting azure-cli-cosmosdb (from azure-cli)\n",
      "  Downloading azure_cli_cosmosdb-0.1.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-keyvault (from azure-cli)\n",
      "  Downloading azure_cli_keyvault-2.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-redis (from azure-cli)\n",
      "  Downloading azure_cli_redis-0.2.7-py2.py3-none-any.whl\n",
      "Collecting azure-cli-consumption (from azure-cli)\n",
      "  Downloading azure_cli_consumption-0.1.3-py2.py3-none-any.whl\n",
      "Collecting azure-cli-acs (from azure-cli)\n",
      "  Downloading azure_cli_acs-2.0.10-py2.py3-none-any.whl\n",
      "Collecting azure-cli-role (from azure-cli)\n",
      "  Downloading azure_cli_role-2.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-cognitiveservices (from azure-cli)\n",
      "  Downloading azure_cli_cognitiveservices-0.1.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-lab (from azure-cli)\n",
      "  Downloading azure_cli_lab-0.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-acr (from azure-cli)\n",
      "  Downloading azure_cli_acr-2.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-billing (from azure-cli)\n",
      "  Downloading azure_cli_billing-0.1.3-py2.py3-none-any.whl\n",
      "Collecting azure-cli-rdbms (from azure-cli)\n",
      "  Downloading azure_cli_rdbms-0.0.5-py2.py3-none-any.whl\n",
      "Collecting azure-cli-feedback (from azure-cli)\n",
      "  Downloading azure_cli_feedback-2.0.6-py2.py3-none-any.whl\n",
      "Collecting azure-cli-storage (from azure-cli)\n",
      "  Downloading azure_cli_storage-2.0.10-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |################################| 51kB 3.8MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting azure-cli-profile (from azure-cli)\n",
      "  Downloading azure_cli_profile-2.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-monitor (from azure-cli)\n",
      "  Downloading azure_cli_monitor-0.0.8-py2.py3-none-any.whl\n",
      "Collecting azure-cli-sql (from azure-cli)\n",
      "  Downloading azure_cli_sql-2.0.7-py2.py3-none-any.whl\n",
      "Collecting azure-cli-command-modules-nspkg>=2.0.0 (from azure-cli-dls->azure-cli)\n",
      "  Downloading azure_cli_command_modules_nspkg-2.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-datalake-store==0.0.12 (from azure-cli-dls->azure-cli)\n",
      "  Downloading azure_datalake_store-0.0.12-py2.py3-none-any.whl (46kB)\n",
      "\u001b[K    100% |################################| 51kB 6.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-datalake-store==0.1.6 (from azure-cli-dls->azure-cli)\n",
      "  Downloading azure_mgmt_datalake_store-0.1.6-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-trafficmanager==0.30.0 (from azure-cli-network->azure-cli)\n",
      "  Downloading azure_mgmt_trafficmanager-0.30.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-dns==1.0.1 (from azure-cli-network->azure-cli)\n",
      "  Downloading azure_mgmt_dns-1.0.1-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-resource==1.1.0 (from azure-cli-network->azure-cli)\n",
      "  Using cached azure_mgmt_resource-1.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-network==1.2.0 (from azure-cli-network->azure-cli)\n",
      "  Downloading azure_mgmt_network-1.2.0-py2.py3-none-any.whl (1.1MB)\n",
      "\u001b[K    100% |################################| 1.1MB 1.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-authorization==0.30.0rc6 (from azure-cli-resource->azure-cli)\n",
      "  Downloading azure_mgmt_authorization-0.30.0rc6-py2.py3-none-any.whl\n",
      "Collecting azure-nspkg>=2.0.0 (from azure-cli-nspkg>=2.0.0->azure-cli)\n",
      "  Downloading azure_nspkg-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-cdn==0.30.2 (from azure-cli-cdn->azure-cli)\n",
      "  Downloading azure_mgmt_cdn-0.30.2-py2.py3-none-any.whl (50kB)\n",
      "\u001b[K    100% |################################| 51kB 6.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-servicefabric==5.6.130 (from azure-cli-sf->azure-cli)\n",
      "  Downloading azure_servicefabric-5.6.130-py2.py3-none-any.whl (283kB)\n",
      "\u001b[K    100% |################################| 286kB 3.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting adal>=0.4.3 (from azure-cli-sf->azure-cli)\n",
      "  Downloading adal-0.4.5-py2.py3-none-any.whl (49kB)\n",
      "\u001b[K    100% |################################| 51kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting mock>=2.0.0 (from azure-cli-sf->azure-cli)\n",
      "  Downloading mock-2.0.0-py2.py3-none-any.whl (56kB)\n",
      "\u001b[K    100% |################################| 61kB 7.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pip (from azure-cli-component->azure-cli)\n",
      "  Downloading pip-9.0.1-py2.py3-none-any.whl (1.3MB)\n",
      "\u001b[K    100% |################################| 1.3MB 1.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting vsts-cd-manager (from azure-cli-appservice->azure-cli)\n",
      "  Downloading vsts-cd-manager-0.118.0.tar.gz\n",
      "Collecting urllib3[secure]>=1.18 (from azure-cli-appservice->azure-cli)\n",
      "  Downloading urllib3-1.21.1-py2.py3-none-any.whl (131kB)\n",
      "\u001b[K    100% |################################| 133kB 5.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting xmltodict (from azure-cli-appservice->azure-cli)\n",
      "  Downloading xmltodict-0.11.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-web==0.32.0 (from azure-cli-appservice->azure-cli)\n",
      "  Downloading azure_mgmt_web-0.32.0-py2.py3-none-any.whl (257kB)\n",
      "\u001b[K    100% |################################| 266kB 3.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-containerregistry==0.3.0 (from azure-cli-appservice->azure-cli)\n",
      "  Downloading azure_mgmt_containerregistry-0.3.0-py2.py3-none-any.whl (73kB)\n",
      "\u001b[K    100% |################################| 81kB 10.4MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting pyOpenSSL (from azure-cli-appservice->azure-cli)\n",
      "  Downloading pyOpenSSL-17.1.0-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |################################| 61kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-datalake-analytics==0.1.6 (from azure-cli-dla->azure-cli)\n",
      "  Downloading azure_mgmt_datalake_analytics-0.1.6-py2.py3-none-any.whl (132kB)\n",
      "\u001b[K    100% |################################| 133kB 6.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting jmespath (from azure-cli-interactive->azure-cli)\n",
      "  Downloading jmespath-0.9.3-py2.py3-none-any.whl\n",
      "Collecting pyyaml (from azure-cli-interactive->azure-cli)\n",
      "  Downloading PyYAML-3.12.tar.gz (253kB)\n",
      "\u001b[K    100% |################################| 256kB 4.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting prompt-toolkit (from azure-cli-interactive->azure-cli)\n",
      "  Downloading prompt_toolkit-1.0.14-py2-none-any.whl (248kB)\n",
      "\u001b[K    100% |################################| 256kB 3.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting applicationinsights (from azure-cli-interactive->azure-cli)\n",
      "  Downloading applicationinsights-0.10.0.tar.gz\n",
      "Collecting six (from azure-cli-interactive->azure-cli)\n",
      "  Downloading six-1.10.0-py2.py3-none-any.whl\n",
      "Collecting whoosh (from azure-cli-find->azure-cli)\n",
      "  Downloading Whoosh-2.7.4-py2.py3-none-any.whl (468kB)\n",
      "\u001b[K    100% |################################| 471kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-iothub==0.2.2 (from azure-cli-iot->azure-cli)\n",
      "  Downloading azure_mgmt_iothub-0.2.2-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-compute==2.0.0 (from azure-cli-vm->azure-cli)\n",
      "  Downloading azure_mgmt_compute-2.0.0-py2.py3-none-any.whl (538kB)\n",
      "\u001b[K    100% |################################| 542kB 2.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-keyvault==0.40.0 (from azure-cli-vm->azure-cli)\n",
      "  Downloading azure_mgmt_keyvault-0.40.0-py2.py3-none-any.whl\n",
      "Collecting azure-multiapi-storage==0.1.0 (from azure-cli-vm->azure-cli)\n",
      "  Downloading azure_multiapi_storage-0.1.0-py2.py3-none-any.whl (333kB)\n",
      "\u001b[K    100% |################################| 337kB 2.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-keyvault==0.3.4 (from azure-cli-vm->azure-cli)\n",
      "  Downloading azure_keyvault-0.3.4-py2.py3-none-any.whl (96kB)\n",
      "\u001b[K    100% |################################| 102kB 10.7MB/s a 0:00:01\n",
      "\u001b[?25hCollecting requests (from azure-cli-core->azure-cli)\n",
      "  Downloading requests-2.18.1-py2.py3-none-any.whl (88kB)\n",
      "\u001b[K    100% |################################| 92kB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting msrest>=0.4.4 (from azure-cli-core->azure-cli)\n",
      "  Downloading msrest-0.4.11-py2.py3-none-any.whl\n",
      "Collecting pygments (from azure-cli-core->azure-cli)\n",
      "  Downloading Pygments-2.2.0-py2.py3-none-any.whl (841kB)\n",
      "\u001b[K    100% |################################| 849kB 1.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tabulate==0.7.7 (from azure-cli-core->azure-cli)\n",
      "  Downloading tabulate-0.7.7-py2.py3-none-any.whl\n",
      "Collecting msrestazure>=0.4.7 (from azure-cli-core->azure-cli)\n",
      "  Downloading msrestazure-0.4.11-py2.py3-none-any.whl\n",
      "Collecting argcomplete>=1.8.0 (from azure-cli-core->azure-cli)\n",
      "  Downloading argcomplete-1.8.2-py2.py3-none-any.whl\n",
      "Collecting colorama (from azure-cli-core->azure-cli)\n",
      "  Downloading colorama-0.3.9-py2.py3-none-any.whl\n",
      "Collecting humanfriendly (from azure-cli-core->azure-cli)\n",
      "  Downloading humanfriendly-4.3-py2.py3-none-any.whl (64kB)\n",
      "\u001b[K    100% |################################| 71kB 9.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting paramiko (from azure-cli-core->azure-cli)\n",
      "  Downloading paramiko-2.2.1-py2.py3-none-any.whl (176kB)\n",
      "\u001b[K    100% |################################| 184kB 6.1MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-batch==3.0.0 (from azure-cli-batch->azure-cli)\n",
      "  Downloading azure_batch-3.0.0-py2.py3-none-any.whl (281kB)\n",
      "\u001b[K    100% |################################| 286kB 4.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-batch==4.0.0 (from azure-cli-batch->azure-cli)\n",
      "  Downloading azure_mgmt_batch-4.0.0-py2.py3-none-any.whl\n",
      "Collecting pydocumentdb>=2.0.1 (from azure-cli-cosmosdb->azure-cli)\n",
      "  Downloading pydocumentdb-2.2.0-py2-none-any.whl (87kB)\n",
      "\u001b[K    100% |################################| 92kB 8.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-documentdb==0.1.3 (from azure-cli-cosmosdb->azure-cli)\n",
      "  Downloading azure_mgmt_documentdb-0.1.3-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-redis==1.0.0 (from azure-cli-redis->azure-cli)\n",
      "  Downloading azure_mgmt_redis-1.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-consumption==0.1.0 (from azure-cli-consumption->azure-cli)\n",
      "  Downloading azure_mgmt_consumption-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-graphrbac==0.30.0rc6 (from azure-cli-acs->azure-cli)\n",
      "  Downloading azure_graphrbac-0.30.0rc6-py2.py3-none-any.whl (43kB)\n",
      "\u001b[K    100% |################################| 51kB 10.7MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting scp (from azure-cli-acs->azure-cli)\n",
      "  Downloading scp-0.10.2-py2.py3-none-any.whl\n",
      "Collecting sshtunnel (from azure-cli-acs->azure-cli)\n",
      "  Downloading sshtunnel-0.1.2.tar.gz\n",
      "Collecting pytz (from azure-cli-role->azure-cli)\n",
      "  Downloading pytz-2017.2-py2.py3-none-any.whl (484kB)\n",
      "\u001b[K    100% |################################| 491kB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-cognitiveservices==1.0.0 (from azure-cli-cognitiveservices->azure-cli)\n",
      "  Downloading azure_mgmt_cognitiveservices-1.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-devtestlabs==2.0.0 (from azure-cli-lab->azure-cli)\n",
      "  Downloading azure_mgmt_devtestlabs-2.0.0-py2.py3-none-any.whl (182kB)\n",
      "\u001b[K    100% |################################| 184kB 6.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-storage==1.0.0rc1 (from azure-cli-acr->azure-cli)\n",
      "  Downloading azure_mgmt_storage-1.0.0rc1-py2.py3-none-any.whl (61kB)\n",
      "\u001b[K    100% |################################| 61kB 9.3MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-billing==0.1.0 (from azure-cli-billing->azure-cli)\n",
      "  Downloading azure_mgmt_billing-0.1.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-rdbms==0.1.0 (from azure-cli-rdbms->azure-cli)\n",
      "  Downloading azure_mgmt_rdbms-0.1.0-py2.py3-none-any.whl (79kB)\n",
      "\u001b[K    100% |################################| 81kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-mgmt-monitor==0.2.1 (from azure-cli-monitor->azure-cli)\n",
      "  Downloading azure_mgmt_monitor-0.2.1-py2.py3-none-any.whl (62kB)\n",
      "\u001b[K    100% |################################| 71kB 9.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting azure-monitor==0.3.0 (from azure-cli-monitor->azure-cli)\n",
      "  Downloading azure_monitor-0.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-sql==0.6.0 (from azure-cli-sql->azure-cli)\n",
      "  Downloading azure_mgmt_sql-0.6.0-py2.py3-none-any.whl (118kB)\n",
      "\u001b[K    100% |################################| 122kB 7.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting futures; python_version <= \"2.7\" (from azure-datalake-store==0.0.12->azure-cli-dls->azure-cli)\n",
      "  Downloading futures-3.1.1-py2-none-any.whl\n",
      "Collecting cffi (from azure-datalake-store==0.0.12->azure-cli-dls->azure-cli)\n",
      "  Downloading cffi-1.10.0-cp27-cp27mu-manylinux1_x86_64.whl (392kB)\n",
      "\u001b[K    100% |################################| 399kB 2.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pathlib2; python_version < \"3.4\" (from azure-datalake-store==0.0.12->azure-cli-dls->azure-cli)\n",
      "  Downloading pathlib2-2.3.0-py2.py3-none-any.whl\n",
      "Collecting azure-common~=1.1.5 (from azure-mgmt-datalake-store==0.1.6->azure-cli-dls->azure-cli)\n",
      "  Downloading azure_common-1.1.6-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-datalake-nspkg>=2.0.0 (from azure-mgmt-datalake-store==0.1.6->azure-cli-dls->azure-cli)\n",
      "  Downloading azure_mgmt_datalake_nspkg-2.0.0-py2.py3-none-any.whl\n",
      "Collecting azure-mgmt-nspkg>=2.0.0 (from azure-mgmt-trafficmanager==0.30.0->azure-cli-network->azure-cli)\n",
      "  Downloading azure_mgmt_nspkg-2.0.0-py2.py3-none-any.whl\n",
      "Collecting python-dateutil>=2.1.0 (from adal>=0.4.3->azure-cli-sf->azure-cli)\n",
      "  Downloading python_dateutil-2.6.1-py2.py3-none-any.whl (194kB)\n",
      "\u001b[K    100% |################################| 194kB 5.0MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting cryptography>=1.1.0 (from adal>=0.4.3->azure-cli-sf->azure-cli)\n",
      "  Downloading cryptography-1.9.tar.gz (409kB)\n",
      "\u001b[K    100% |################################| 419kB 2.6MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting PyJWT>=1.0.0 (from adal>=0.4.3->azure-cli-sf->azure-cli)\n",
      "  Downloading PyJWT-1.5.2-py2.py3-none-any.whl\n",
      "Collecting funcsigs>=1; python_version < \"3.3\" (from mock>=2.0.0->azure-cli-sf->azure-cli)\n",
      "  Downloading funcsigs-1.0.2-py2.py3-none-any.whl\n",
      "Collecting pbr>=0.11 (from mock>=2.0.0->azure-cli-sf->azure-cli)\n",
      "  Downloading pbr-3.1.1-py2.py3-none-any.whl (99kB)\n",
      "\u001b[K    100% |################################| 102kB 9.2MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting idna>=2.0.0; python_version <= \"2.7\" and extra == \"secure\" (from urllib3[secure]>=1.18->azure-cli-appservice->azure-cli)\n",
      "  Downloading idna-2.5-py2.py3-none-any.whl (55kB)\n",
      "\u001b[K    100% |################################| 61kB 10.3MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting certifi; extra == \"secure\" (from urllib3[secure]>=1.18->azure-cli-appservice->azure-cli)\n",
      "  Downloading certifi-2017.4.17-py2.py3-none-any.whl (375kB)\n",
      "\u001b[K    100% |################################| 378kB 2.9MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting ipaddress; python_version <= \"2.7\" and extra == \"secure\" (from urllib3[secure]>=1.18->azure-cli-appservice->azure-cli)\n",
      "  Downloading ipaddress-1.0.18-py2-none-any.whl\n",
      "Collecting wcwidth (from prompt-toolkit->azure-cli-interactive->azure-cli)\n",
      "  Downloading wcwidth-0.1.7-py2.py3-none-any.whl\n",
      "Collecting chardet<3.1.0,>=3.0.2 (from requests->azure-cli-core->azure-cli)\n",
      "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133kB)\n",
      "\u001b[K    100% |################################| 143kB 8.4MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.5.0 (from msrest>=0.4.4->azure-cli-core->azure-cli)\n",
      "  Downloading requests_oauthlib-0.8.0-py2.py3-none-any.whl\n",
      "Collecting isodate>=0.5.4 (from msrest>=0.4.4->azure-cli-core->azure-cli)\n",
      "  Downloading isodate-0.5.4.tar.gz\n",
      "Collecting enum34>=1.0.4; python_version < \"3.4\" (from msrest>=0.4.4->azure-cli-core->azure-cli)\n",
      "  Downloading enum34-1.1.6-py2-none-any.whl\n",
      "Collecting keyring>=5.6 (from msrestazure>=0.4.7->azure-cli-core->azure-cli)\n",
      "  Downloading keyring-10.4.0-py2.py3-none-any.whl\n",
      "Collecting monotonic; python_version == \"2.6\" or python_version == \"2.7\" or python_version == \"3.0\" or python_version == \"3.1\" or python_version == \"3.2\" (from humanfriendly->azure-cli-core->azure-cli)\n",
      "  Downloading monotonic-1.3-py2.py3-none-any.whl\n",
      "Collecting pynacl>=1.0.1 (from paramiko->azure-cli-core->azure-cli)\n",
      "  Downloading PyNaCl-1.1.2-cp27-cp27mu-manylinux1_x86_64.whl (539kB)\n",
      "\u001b[K    100% |################################| 542kB 2.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pyasn1>=0.1.7 (from paramiko->azure-cli-core->azure-cli)\n",
      "  Downloading pyasn1-0.2.3-py2.py3-none-any.whl (53kB)\n",
      "\u001b[K    100% |################################| 61kB 11.5MB/s ta 0:00:01\n",
      "\u001b[?25hCollecting bcrypt>=3.1.3 (from paramiko->azure-cli-core->azure-cli)\n",
      "  Downloading bcrypt-3.1.3-cp27-cp27mu-manylinux1_x86_64.whl (57kB)\n",
      "\u001b[K    100% |################################| 61kB 9.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting pycparser (from cffi->azure-datalake-store==0.0.12->azure-cli-dls->azure-cli)\n",
      "  Downloading pycparser-2.18.tar.gz (245kB)\n",
      "\u001b[K    100% |################################| 256kB 4.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting scandir; python_version < \"3.5\" (from pathlib2; python_version < \"3.4\"->azure-datalake-store==0.0.12->azure-cli-dls->azure-cli)\n",
      "Collecting asn1crypto>=0.21.0 (from cryptography>=1.1.0->adal>=0.4.3->azure-cli-sf->azure-cli)\n",
      "  Downloading asn1crypto-0.22.0-py2.py3-none-any.whl (97kB)\n",
      "\u001b[K    100% |################################| 102kB 10.0MB/s a 0:00:01\n",
      "\u001b[?25hCollecting oauthlib>=0.6.2 (from requests-oauthlib>=0.5.0->msrest>=0.4.4->azure-cli-core->azure-cli)\n",
      "  Downloading oauthlib-2.0.2.tar.gz (125kB)\n",
      "\u001b[K    100% |################################| 133kB 8.2MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting secretstorage; sys_platform == \"linux2\" or sys_platform == \"linux\" (from keyring>=5.6->msrestazure>=0.4.7->azure-cli-core->azure-cli)\n",
      "  Downloading SecretStorage-2.3.1.tar.gz\n",
      "Building wheels for collected packages: vsts-cd-manager, pyyaml, applicationinsights, sshtunnel, cryptography, isodate, pycparser, oauthlib, secretstorage\n",
      "  Running setup.py bdist_wheel for vsts-cd-manager ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/6f/69/58/23fc80b987a15698bee59dcd3595eabb7f838396c0cc4cc0a6\n",
      "  Running setup.py bdist_wheel for pyyaml ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/2c/f7/79/13f3a12cd723892437c0cfbde1230ab4d82947ff7b3839a4fc\n",
      "  Running setup.py bdist_wheel for applicationinsights ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/5d/00/c9/6cae03c0f0dd766574b08bee1a05f91f88d68e6990a1e4282b\n",
      "  Running setup.py bdist_wheel for sshtunnel ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/2f/92/75/a2db92ad2905bfc8663e980b8963625b4dd728fd64523f1da9\n",
      "  Running setup.py bdist_wheel for cryptography ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/ff/a5/ef/186bb4f6a89ef0bb8373bf53e5c9884b96722f0857bd3111b8\n",
      "  Running setup.py bdist_wheel for isodate ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/61/c0/d2/6b4a10c222ba9261ab9872a8f05d471652962284e8c677e5e7\n",
      "  Running setup.py bdist_wheel for pycparser ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/95/14/9a/5e7b9024459d2a6600aaa64e0ba485325aff7a9ac7489db1b6\n",
      "  Running setup.py bdist_wheel for oauthlib ... \u001b[?25l-\b \b\\\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/84/98/7a/fba7268f61097bea6081cbe5480bc439b38975748ea7684fd5\n",
      "  Running setup.py bdist_wheel for secretstorage ... \u001b[?25l-\b \bdone\n",
      "\u001b[?25h  Stored in directory: /home/nbuser/.cache/pip/wheels/c7/58/c5/d09bed2136a4e88ed403f68c91f86293b46eecb719c00ef0d6\n",
      "Successfully built vsts-cd-manager pyyaml applicationinsights sshtunnel cryptography isodate pycparser oauthlib secretstorage\n",
      "Installing collected packages: azure-nspkg, azure-cli-nspkg, azure-cli-command-modules-nspkg, jmespath, idna, six, asn1crypto, enum34, ipaddress, pycparser, cffi, cryptography, pyOpenSSL, certifi, urllib3, chardet, requests, pyyaml, oauthlib, requests-oauthlib, isodate, msrest, pip, applicationinsights, pygments, tabulate, secretstorage, keyring, python-dateutil, PyJWT, adal, msrestazure, argcomplete, colorama, monotonic, humanfriendly, pynacl, pyasn1, bcrypt, paramiko, azure-cli-core, futures, scandir, pathlib2, azure-datalake-store, azure-common, azure-mgmt-nspkg, azure-mgmt-datalake-nspkg, azure-mgmt-datalake-store, azure-cli-dls, azure-mgmt-trafficmanager, azure-mgmt-dns, azure-mgmt-resource, azure-mgmt-network, azure-cli-network, azure-mgmt-authorization, azure-cli-resource, azure-mgmt-cdn, azure-cli-cdn, azure-servicefabric, funcsigs, pbr, mock, azure-cli-sf, azure-cli-component, vsts-cd-manager, xmltodict, azure-mgmt-web, azure-mgmt-containerregistry, azure-cli-appservice, azure-mgmt-datalake-analytics, azure-cli-dla, wcwidth, prompt-toolkit, azure-cli-interactive, whoosh, azure-cli-find, azure-mgmt-iothub, azure-cli-iot, azure-mgmt-compute, azure-mgmt-keyvault, azure-multiapi-storage, azure-keyvault, azure-cli-vm, azure-cli-cloud, azure-cli-configure, azure-batch, azure-mgmt-batch, azure-cli-batch, pydocumentdb, azure-mgmt-documentdb, azure-cli-cosmosdb, azure-cli-keyvault, azure-mgmt-redis, azure-cli-redis, azure-mgmt-consumption, azure-cli-consumption, azure-graphrbac, scp, sshtunnel, azure-cli-acs, pytz, azure-cli-role, azure-mgmt-cognitiveservices, azure-cli-cognitiveservices, azure-mgmt-devtestlabs, azure-cli-lab, azure-mgmt-storage, azure-cli-acr, azure-mgmt-billing, azure-cli-billing, azure-mgmt-rdbms, azure-cli-rdbms, azure-cli-feedback, azure-cli-storage, azure-cli-profile, azure-mgmt-monitor, azure-monitor, azure-cli-monitor, azure-mgmt-sql, azure-cli-sql, azure-cli\n",
      "Successfully installed PyJWT-1.5.2 adal-0.4.5 applicationinsights-0.10.0 argcomplete-1.8.2 asn1crypto-0.22.0 azure-batch-3.0.0 azure-cli-2.0.10 azure-cli-acr-2.0.8 azure-cli-acs-2.0.10 azure-cli-appservice-0.1.10 azure-cli-batch-3.0.3 azure-cli-billing-0.1.3 azure-cli-cdn-0.0.6 azure-cli-cloud-2.0.6 azure-cli-cognitiveservices-0.1.6 azure-cli-command-modules-nspkg-2.0.1 azure-cli-component-2.0.6 azure-cli-configure-2.0.10 azure-cli-consumption-0.1.3 azure-cli-core-2.0.11 azure-cli-cosmosdb-0.1.10 azure-cli-dla-0.0.10 azure-cli-dls-0.0.10 azure-cli-feedback-2.0.6 azure-cli-find-0.2.6 azure-cli-interactive-0.3.6 azure-cli-iot-0.1.9 azure-cli-keyvault-2.0.8 azure-cli-lab-0.0.8 azure-cli-monitor-0.0.8 azure-cli-network-2.0.10 azure-cli-nspkg-3.0.1 azure-cli-profile-2.0.8 azure-cli-rdbms-0.0.5 azure-cli-redis-0.2.7 azure-cli-resource-2.0.10 azure-cli-role-2.0.8 azure-cli-sf-1.0.5 azure-cli-sql-2.0.7 azure-cli-storage-2.0.10 azure-cli-vm-2.0.10 azure-common-1.1.6 azure-datalake-store-0.0.12 azure-graphrbac-0.30.0rc6 azure-keyvault-0.3.4 azure-mgmt-authorization-0.30.0rc6 azure-mgmt-batch-4.0.0 azure-mgmt-billing-0.1.0 azure-mgmt-cdn-0.30.2 azure-mgmt-cognitiveservices-1.0.0 azure-mgmt-compute-1.0.0 azure-mgmt-consumption-0.1.0 azure-mgmt-containerregistry-0.3.0 azure-mgmt-datalake-analytics-0.1.6 azure-mgmt-datalake-nspkg-2.0.0 azure-mgmt-datalake-store-0.1.6 azure-mgmt-devtestlabs-2.0.0 azure-mgmt-dns-1.0.1 azure-mgmt-documentdb-0.1.3 azure-mgmt-iothub-0.2.2 azure-mgmt-keyvault-0.40.0 azure-mgmt-monitor-0.2.1 azure-mgmt-network-1.2.0 azure-mgmt-nspkg-2.0.0 azure-mgmt-rdbms-0.1.0 azure-mgmt-redis-1.0.0 azure-mgmt-resource-1.1.0 azure-mgmt-sql-0.6.0 azure-mgmt-storage-1.0.0rc1 azure-mgmt-trafficmanager-0.30.0 azure-mgmt-web-0.32.0 azure-monitor-0.3.0 azure-multiapi-storage-0.1.0 azure-nspkg-2.0.0 azure-servicefabric-5.6.130 bcrypt-3.1.3 certifi-2017.4.17 cffi-1.10.0 chardet-3.0.4 colorama-0.3.9 cryptography-1.9 enum34-1.1.6 funcsigs-1.0.2 futures-3.1.1 humanfriendly-4.3 idna-2.5 ipaddress-1.0.18 isodate-0.5.4 jmespath-0.9.3 keyring-10.4.0 mock-2.0.0 monotonic-1.3 msrest-0.4.11 msrestazure-0.4.7 oauthlib-2.0.2 paramiko-2.2.1 pathlib2-2.2.1 pbr-3.1.1 pip-9.0.1 prompt-toolkit-1.0.14 pyOpenSSL-17.1.0 pyasn1-0.2.3 pycparser-2.18 pydocumentdb-2.2.0 pygments-2.2.0 pynacl-1.1.2 python-dateutil-2.6.1 pytz-2017.2 pyyaml-3.12 requests-2.18.1 requests-oauthlib-0.8.0 scandir-1.5 scp-0.10.2 secretstorage-2.3.1 six-1.10.0 sshtunnel-0.1.2 tabulate-0.7.7 urllib3-1.21.1 vsts-cd-manager-0.118.0 wcwidth-0.1.7 whoosh-2.7.4 xmltodict-0.11.0\n"
     ]
    }
   ],
   "source": [
    "!pip install -I azure-cli"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll create an alias for invoking Batch Shipyard which points to a `config` directory which will hold our json config files (this directory will be created at a later step)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%alias shipyard SHIPYARD_CONFIGDIR=config python $HOME/batch-shipyard/shipyard.py %l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that everything is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shipyard.py, version 2.8.0\r\n"
     ]
    }
   ],
   "source": [
    "shipyard --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Azure account login\n",
    "The command below will initiate a login to your Azure account. You will see a url to browse to where you will enter the specified code. This will log you into the Azure account within the Azure CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mTo sign in, use a web browser to open the page https://aka.ms/devicelogin and enter the code FW2UXEQDJ to authenticate.\u001b[0m\n",
      "CloudName    Name                                        State     TenantId                              IsDefault\n",
      "-----------  ------------------------------------------  --------  ------------------------------------  -----------\n",
      "AzureCloud   AI Immersion Workshop Support Subscription  Disabled  72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Boston DS Dev                               Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47  True\n",
      "AzureCloud   Azure Internal - London                     Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Team Danielle Internal                      Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Visual Studio Enterprise                    Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Microsoft Azure Internal - Demos            Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Team Ilan                                   Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n",
      "AzureCloud   Marketing Automation                        Enabled   72f988bf-86f1-41af-91ab-2d7cd011db47\n"
     ]
    }
   ],
   "source": [
    "!az login -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have multiple subscriptions you can select the one you need with the command below. This will not be necessary for your assigned Azure Pass account for the workshop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "selected_subscription = '\"Team Danielle Internal\"' #'\"YOUR TEAM SUBSCRIPTION\"' # Replace with the name of your subscription\n",
    "!az account set --subscription $selected_subscription"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you cannot login with the Azure CLI, you can create Azure Batch and Storage accounts on the [Azure Portal](https://portal.azure.com).\n",
    "- [Instructions for creating an Azure Batch Account](https://docs.microsoft.com/en-us/azure/batch/batch-account-create-portal#batch-service-mode)\n",
    "- [Instructions for creating an Azure Storage Account](https://docs.microsoft.com/en-us/azure/storage/storage-create-storage-account#create-a-storage-account) (You can create an \"Auto Storage\" account at the same time as your Batch Account on the portal instead)\n",
    "\n",
    "Please pay attention to special instructions regarding Azure Portal created accounts below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will need to register the Azure Batch service as a resource provider for the Azure subscription. The following will do so and poll until the registration process has completed. This will take approximately 30 seconds to complete.\n",
    "\n",
    "**Note:** This registration process needs to be performed only once for the Azure subscription. If you created your Azure Batch account via the Azure Portal, you do not need to perform this action as it is done automatically for you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# register resource provider with subscription\n",
    "print('Registering Microsoft.Batch with subscription. Please be patient for this process.')\n",
    "!az provider register -n Microsoft.Batch\n",
    "\n",
    "# poll until registration completed\n",
    "while True:\n",
    "    status = !az provider show -n Microsoft.Batch -o table\n",
    "    if status[-1].split()[-1] == 'Registered':\n",
    "        print('\\n'.join(status))\n",
    "        break\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will define the various names for the resources needed to run Azure Batch jobs.\n",
    "\n",
    "**Note:** If you manually created your accounts on the Azure Portal, you will need to modify `GROUP_NAME`, `BATCH_ACCOUNT_NAME` and `STORAGE_ACCOUNT_NAME` accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import uuid\n",
    "import random\n",
    "\n",
    "def write_json_to_file(json_dict, filename):\n",
    "    \"\"\" Simple function to write JSON dictionaries to files\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(json_dict, outfile)\n",
    "\n",
    "LOCATION = 'eastus' # We are setting everything up in East US\n",
    "                    # Be aware that you need to set things up in a region that has GPU VMs (N-Series)\n",
    "\n",
    "# load base CNTK image from Docker hub\n",
    "IMAGE_NAME = \"microsoft/cntk:2.0-gpu-python3.5-cuda8.0-cudnn5.1\"\n",
    "\n",
    "# Please do not modify below unless you created your accounts on the Azure Portal\n",
    "short_uuid = str(uuid.uuid4())[:8]\n",
    "\n",
    "GROUP_NAME = \"batch{uuid}rg\".format(uuid=short_uuid)\n",
    "BATCH_ACCOUNT_NAME = \"batch{uuid}ba\".format(uuid=short_uuid)\n",
    "STORAGE_ACCOUNT_NAME = \"batch{uuid}st\".format(uuid=short_uuid)\n",
    "STORAGE_ALIAS = \"mystorageaccount\"\n",
    "STORAGE_ENDPOINT = \"core.windows.net\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Resource Group\n",
    "Azure encourages the use of resource groups to organise all the Azure components you deploy. That way it is easier to find them but also we can deleted a number of resources simply by deleting the Resource Group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Location    Name\r\n",
      "----------  ---------------\r\n",
      "eastus      batch3c635ca4rg\r\n"
     ]
    }
   ],
   "source": [
    "!az group create -n $GROUP_NAME -l $LOCATION -o table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Batch and Storage accounts\n",
    "Here we simply crate the Batch and Storage accounts. Once we have created the accounts we can the use the Azure CLI to query them and obtain the **batch_account_key**, **batch_service_url** and **storage_account_key** which we will need for our Batch Shipyard configuration files later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storage account batch3c635ca4st provisioning state: Succeeded\n"
     ]
    }
   ],
   "source": [
    "json_data = !az storage account create -l $LOCATION -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME --sku Standard_LRS\n",
    "print('Storage account {} provisioning state: {}'.format(STORAGE_ACCOUNT_NAME, json.loads(''.join(json_data))['provisioningState']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch account batch3c635ca4ba provisioning state: Succeeded\n"
     ]
    }
   ],
   "source": [
    "json_data = !az batch account create -l $LOCATION -n $BATCH_ACCOUNT_NAME -g $GROUP_NAME --storage-account $STORAGE_ACCOUNT_NAME\n",
    "print('Batch account {} provisioning state: {}'.format(BATCH_ACCOUNT_NAME, json.loads(''.join(json_data))['provisioningState']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we retrieve the **batch_account_key**, **batch_service_url** and **storage_account_key** which we will need for the Batch Shipyard configuration files further down.\n",
    "\n",
    "**Note:** If you created your Batch and Storage accounts in the Azure Portal, you will need to retrieve your keys in the Portal. Then set `batch_account_key`, `batch_service_url`, and `storage_account_key` to their appropriate values instead of the Azure CLI callouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data = !az batch account keys list -n $BATCH_ACCOUNT_NAME -g $GROUP_NAME\n",
    "batch_account_key = json.loads(''.join(json_data))['primary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data = !az batch account list -g $GROUP_NAME\n",
    "batch_service_url = 'https://'+json.loads(''.join(json_data))[0]['accountEndpoint']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_data = !az storage account keys list -n $STORAGE_ACCOUNT_NAME -g $GROUP_NAME\n",
    "storage_account_key = json.loads(''.join(json_data))[0]['value']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save credentials required for other notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "account_information = {\n",
    "    \"IMAGE_NAME\": IMAGE_NAME,\n",
    "    \"LOCATION\": LOCATION,\n",
    "    \"resource_group\": GROUP_NAME,\n",
    "    \"STORAGE_ALIAS\": STORAGE_ALIAS,\n",
    "    \"storage_account_key\": storage_account_key,\n",
    "    \"storage_account_name\": STORAGE_ACCOUNT_NAME,\n",
    "}\n",
    "write_json_to_file(account_information, 'account_information.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Shiyard configuration\n",
    "In order to execute a job on Batch Shipyard you need a minimum of four configuration files. We will set three of them here and leave the job one for later.\n",
    "* [credentials](#credentials)\n",
    "* [configuration](#configuration)\n",
    "* [pool](#pool)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='credentials'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Credentials\n",
    "Here we define all the credentials necessary for Batch Shipyard to connect to Azure for resource provisioning and executing our jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "credentials = {\n",
    "    \"credentials\": {\n",
    "        \"batch\": {\n",
    "            \"account_key\": batch_account_key,\n",
    "            \"account_service_url\": batch_service_url\n",
    "        },\n",
    "        \"storage\": {\n",
    "            STORAGE_ALIAS : {\n",
    "                    \"account\": STORAGE_ACCOUNT_NAME,\n",
    "                    \"account_key\": storage_account_key,\n",
    "                    \"endpoint\": STORAGE_ENDPOINT\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='configuration'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration\n",
    "The config mainly contains the configuration for Batch Shipyard. Here we simply define the storage alias that Batch Shipyard should use as well as the Docker image to use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"batch_shipyard\": {\n",
    "        \"storage_account_settings\": STORAGE_ALIAS\n",
    "    },\n",
    "    \"global_resources\": {\n",
    "        \"docker_images\": [\n",
    "            IMAGE_NAME\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='pool'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pool\n",
    "This is where we define the properties of the compute pool we wish to create. The configuration below creates a pool that is made up of a three NC6 VM running Ubuntu 16.04. If you wish to run a job that uses GPU accelerated compute, as we will be doing for these notebooks, then you will need to choose a VM from the NC series. Here we will allocate 3 `STANDARD_NC6` instances.\n",
    "\n",
    "Under resource files we are pulling in two scripts that will be run as part of the pool creation. They simply download and prepare the CIFAR10 data. These files can be found in the github repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "POOL_ID = 'gpupool'\n",
    "\n",
    "pool = {\n",
    "    \"pool_specification\": {\n",
    "        \"id\": POOL_ID,\n",
    "        \"vm_configuration\": {\n",
    "            \"platform_image\": {\n",
    "                \"publisher\": \"Canonical\",\n",
    "                \"offer\": \"UbuntuServer\",\n",
    "                \"sku\": \"16.04-LTS\"\n",
    "            },\n",
    "        },\n",
    "        \"vm_size\": \"STANDARD_NC6\",\n",
    "        \"vm_count\": {\n",
    "            \"dedicated\": 3\n",
    "        },\n",
    "        \"ssh\": {\n",
    "            \"username\": \"docker\"\n",
    "        },\n",
    "        \"reboot_on_start_task_failed\": False,\n",
    "        \"block_until_all_global_resources_loaded\": True,\n",
    "        \"resource_files\": [\n",
    "            {\n",
    "                \"file_path\": \"cifar_data_processing.py\",\n",
    "                \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/cifar_data_processing.py\",\n",
    "                \"file_mode\":'0777'\n",
    "            },\n",
    "            {\n",
    "                \"file_path\": \"convert_cifar10.sh\",\n",
    "                \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/convert_cifar10.sh\",\n",
    "                \"file_mode\":'0777'\n",
    "            }\n",
    "        ],\n",
    "         \"additional_node_prep_commands\": [\n",
    "            \"/bin/bash convert_cifar10.sh {} $AZ_BATCH_NODE_SHARED_DIR/data\".format(IMAGE_NAME)\n",
    "        ]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!mkdir -p config # Create config file directory where we will store all our Batch Shipyard configuration files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_json_to_file(credentials, os.path.join('config', 'credentials.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "write_json_to_file(config, os.path.join('config', 'config.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "write_json_to_file(pool, os.path.join('config', 'pool.json'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please run the following cell and copy/paste the information output from the cell into a scratch space (e.g., Notepad), just in case for recovery purposes. Note that this will output credential secrets for your accounts, so do not openly distribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMAGE_NAME = \"microsoft/cntk:2.0-gpu-python3.5-cuda8.0-cudnn5.1\"\n",
      "GROUP_NAME = \"batch3c635ca4rg\"\n",
      "LOCATION = \"eastus\"\n",
      "BATCH_ACCOUNT_NAME = \"batch3c635ca4ba\"\n",
      "batch_account_key = \"dGRaZc+5+SrZdhTIme3FJhNX3lfl95q1ApmOO1N8gfRSc1sHHzyAFDT7JB7Z0lgxuztt0MoAmvPjzQvcpRvr3A==\"\n",
      "batch_service_url = \"https://batch3c635ca4ba.eastus.batch.azure.com\"\n",
      "STORAGE_ACCOUNT_NAME = \"batch3c635ca4st\"\n",
      "STORAGE_ALIAS = \"mystorageaccount\"\n",
      "storage_account_key = \"9WcWTV2nGyKwWr626d860XKmVkqQ9PdVqNq23qGrBDKmHMwL4d9Y0aYHkzmVkTmFe753RrCejZ7+oF01NxgHUg==\"\n"
     ]
    }
   ],
   "source": [
    "print('IMAGE_NAME = \"{}\"'.format(IMAGE_NAME))\n",
    "print('GROUP_NAME = \"{}\"'.format(GROUP_NAME))\n",
    "print('LOCATION = \"{}\"'.format(LOCATION))\n",
    "print('BATCH_ACCOUNT_NAME = \"{}\"'.format(BATCH_ACCOUNT_NAME))\n",
    "print('batch_account_key = \"{}\"'.format(batch_account_key))\n",
    "print('batch_service_url = \"{}\"'.format(batch_service_url))\n",
    "print('STORAGE_ACCOUNT_NAME = \"{}\"'.format(STORAGE_ACCOUNT_NAME))\n",
    "print('STORAGE_ALIAS = \"{}\"'.format(STORAGE_ALIAS))\n",
    "print('storage_account_key = \"{}\"'.format(storage_account_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section6'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Azure Batch Pool\n",
    "Before we do anything we need to create the pool for Batch Shipyard jobs to run on. This can take a little bit of time so please be patient while the compute nodes are allocated from the Azure Cloud and the Docker images are pre-loaded on to the compute nodes.\n",
    "\n",
    "**Note:** As soon as one node enters `ComputeNodeState.idle` then you can proceed to the next notebook. You do not need to wait for all nodes to enter this state to begin the next notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 13:24:52,944 INFO - creating table: shipyardregistry\n",
      "2017-07-12 13:24:53,343 INFO - creating container: shipyardremotefs\n",
      "2017-07-12 13:24:53,566 INFO - creating table: shipyardgr\n",
      "2017-07-12 13:24:53,620 INFO - creating table: shipyarddht\n",
      "2017-07-12 13:24:53,674 INFO - creating table: shipyardimages\n",
      "2017-07-12 13:24:53,729 INFO - creating queue: shipyardgr-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:53,991 INFO - creating container: shipyardtor-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:54,041 INFO - creating table: shipyardtorrentinfo\n",
      "2017-07-12 13:24:54,097 INFO - creating container: shipyardrf-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:54,147 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardregistry\n",
      "2017-07-12 13:24:54,217 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardgr\n",
      "2017-07-12 13:24:54,266 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardperf\n",
      "2017-07-12 13:24:54,314 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyarddht\n",
      "2017-07-12 13:24:54,362 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardimages\n",
      "2017-07-12 13:24:54,411 INFO - clearing queue: shipyardgr-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:54,455 INFO - deleting blobs: shipyardtor-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:54,519 DEBUG - clearing table (pk=batch0e43a94eba$gpupool): shipyardtorrentinfo\n",
      "2017-07-12 13:24:54,568 INFO - deleting blobs: shipyardrf-batch0e43a94eba-gpupool\n",
      "2017-07-12 13:24:54,691 INFO - adding global resource: docker:microsoft/cntk:2.0-gpu-python3.5-cuda8.0-cudnn5.1\n",
      "2017-07-12 13:24:54,799 DEBUG - no virtual network settings specified\n",
      "2017-07-12 13:24:54,799 INFO - NVIDIA Software License accepted\n",
      "2017-07-12 13:24:54,800 DEBUG - downloading NVIDIA driver to resources/nvidia-driver.run\n",
      "2017-07-12 13:24:55,260 DEBUG - wrote 75096990 bytes to resources/nvidia-driver.run\n",
      "2017-07-12 13:24:55,553 DEBUG - downloading NVIDIA docker to resources/nvidia-docker.deb\n",
      "2017-07-12 13:24:56,599 DEBUG - wrote 2266050 bytes to resources/nvidia-docker.deb\n",
      "2017-07-12 13:24:56,889 INFO - uploading file /home/nbuser/batch-shipyard/scripts/docker_jp_block.sh as u'docker_jp_block.sh'\n",
      "2017-07-12 13:24:56,981 INFO - uploading file /home/nbuser/batch-shipyard/scripts/shipyard_blobxfer.sh as u'shipyard_blobxfer.sh'\n",
      "2017-07-12 13:24:57,071 INFO - uploading file /home/nbuser/batch-shipyard/resources/nvidia-driver.run as 'nvidia-driver.run'\n",
      "2017-07-12 13:24:59,851 INFO - uploading file /home/nbuser/batch-shipyard/resources/nvidia-docker.deb as 'nvidia-docker.deb'\n",
      "2017-07-12 13:25:00,033 INFO - uploading file /home/nbuser/batch-shipyard/scripts/shipyard_nodeprep.sh as u'shipyard_nodeprep.sh'\n",
      "2017-07-12 13:25:00,085 INFO - Attempting to create pool: gpupool\n",
      "2017-07-12 13:25:00,366 INFO - Created pool: gpupool\n",
      "2017-07-12 13:25:00,367 INFO - waiting for all nodes in pool gpupool to reach one of: frozenset([<ComputeNodeState.idle: 'idle'>, <ComputeNodeState.preempted: 'preempted'>, <ComputeNodeState.start_task_failed: 'startTaskFailed'>, <ComputeNodeState.unusable: 'unusable'>])\n",
      "2017-07-12 13:25:21,347 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.resizing\n",
      "2017-07-12 13:25:52,820 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.resizing\n",
      "2017-07-12 13:26:24,410 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:26:24,411 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:26:24,411 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:26:24,411 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:26:56,207 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:26:56,207 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:26:56,207 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:26:56,207 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:27,963 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:27:27,963 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:27,963 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:27,963 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:59,895 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:27:59,895 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:59,895 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.starting\n",
      "2017-07-12 13:27:59,895 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:28:31,715 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:28:31,716 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:28:31,716 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:28:31,716 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:03,733 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:29:03,733 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:03,733 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:03,733 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:35,660 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:29:35,661 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:35,661 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:29:35,661 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:07,572 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:30:07,572 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:07,572 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:07,573 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:39,935 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:30:39,935 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:39,935 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:30:39,935 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:11,917 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:31:11,917 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:11,918 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:11,918 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:43,875 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:31:43,875 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:43,875 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:31:43,875 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:15,754 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:32:15,754 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:15,754 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:15,755 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:47,637 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:32:47,637 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:47,637 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:32:47,637 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:19,903 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:33:19,903 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:19,903 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:19,904 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:51,750 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:33:51,750 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:51,750 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:33:51,750 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:23,661 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:34:23,661 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:23,661 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:23,661 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:55,661 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:34:55,662 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:55,662 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:34:55,662 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:35:27,718 DEBUG - waiting for 3 dedicated nodes and 0 low priority nodes to reach desired state in pool gpupool with allocation_state=AllocationState.steady\n",
      "2017-07-12 13:35:27,718 DEBUG - tvm-1392786932_1-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:35:27,718 DEBUG - tvm-1392786932_2-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:35:27,718 DEBUG - tvm-1392786932_3-20170712t132611z: ComputeNodeState.waiting_for_start_task\n",
      "2017-07-12 13:35:59,711 DEBUG - listing nodes for pool gpupool\n",
      "2017-07-12 13:35:59,711 INFO - node_id=tvm-1392786932_1-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.6 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n",
      "2017-07-12 13:35:59,711 INFO - node_id=tvm-1392786932_2-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.5 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n",
      "2017-07-12 13:35:59,711 INFO - node_id=tvm-1392786932_3-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.4 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n",
      "2017-07-12 13:35:59,711 INFO - generating ssh key pair to path: .\n",
      "Generating public/private rsa key pair.\n",
      "Your identification has been saved in id_rsa_shipyard.\n",
      "Your public key has been saved in id_rsa_shipyard.pub.\n",
      "The key fingerprint is:\n",
      "SHA256:f+z1L4dmEtr/HKxZ8apZJq0WmiYGuahiWqsdJRtWBa0 nbuser@nbserver\n",
      "The key's randomart image is:\n",
      "+---[RSA 2048]----+\n",
      "|    .o.          |\n",
      "|     ..          |\n",
      "|    ..           |\n",
      "|   .E            |\n",
      "|  + .  .S      . |\n",
      "| . =  o  . .o.. o|\n",
      "|  +  . o  .=+o==.|\n",
      "|.+ o. . o =o+BO+o|\n",
      "|=o+.   . o .=Oo+*|\n",
      "+----[SHA256]-----+\n",
      "2017-07-12 13:35:59,802 INFO - adding user docker to node tvm-1392786932_1-20170712t132611z in pool gpupool, expiry=2017-08-11 13:35:59.802103\n",
      "No handlers could be found for logger \"msrest.serialization\"\n",
      "2017-07-12 13:36:00,909 INFO - adding user docker to node tvm-1392786932_2-20170712t132611z in pool gpupool, expiry=2017-08-11 13:36:00.909544\n",
      "2017-07-12 13:36:01,889 INFO - adding user docker to node tvm-1392786932_3-20170712t132611z in pool gpupool, expiry=2017-08-11 13:36:01.889504\n",
      "2017-07-12 13:36:03,295 INFO - node tvm-1392786932_1-20170712t132611z: ip 52.168.26.170 port 50002\n",
      "2017-07-12 13:36:03,494 INFO - node tvm-1392786932_2-20170712t132611z: ip 52.168.26.170 port 50001\n",
      "2017-07-12 13:36:03,682 INFO - node tvm-1392786932_3-20170712t132611z: ip 52.168.26.170 port 50000\n"
     ]
    }
   ],
   "source": [
    "shipyard pool add -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the pool is created we can confirm everything by running the command below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-12 13:36:47,507 DEBUG - listing nodes for pool gpupool\n",
      "2017-07-12 13:36:47,812 INFO - node_id=tvm-1392786932_1-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.6 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n",
      "2017-07-12 13:36:47,812 INFO - node_id=tvm-1392786932_2-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.5 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n",
      "2017-07-12 13:36:47,812 INFO - node_id=tvm-1392786932_3-20170712t132611z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.4 vm_size=standard_nc6 dedicated=True total_tasks_run=0 running_tasks_count=0 total_tasks_succeeded=0]\n"
     ]
    }
   ],
   "source": [
    "shipyard pool listnodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section7'></a>\n",
    "## View Resources on Azure Portal or Batch Labs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want a graphical interface for your Azure Batch resources, you can view them on the [Azure Portal](https://portal.azure.com) or with [Batch Labs](https://github.com/Azure/BatchLabs)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Next notebook: Single GPU Training](02_Single_GPU_Training.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
