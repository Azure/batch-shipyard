{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VII - Tensorboard Visualization\n",
    "This notebook will show how to create an SSH tunnel from the machine running the Notebook to the compute node of a task that is running or has run a task that has generated [Tensorboard](https://www.tensorflow.org/get_started/summaries_and_tensorboard) summary compatible output.\n",
    "\n",
    "**NOTE:** This notebook cannot be run on Azure notebooks due to restrictions. Please run this notebook locally. If you are running this notebook on Windows, please ensure you have `ssh.exe` in your `%PATH%`. You can download OpenSSH binaries for Windows [here](https://github.com/PowerShell/Win32-OpenSSH/releases).\n",
    "\n",
    "* [Setup](#section1)\n",
    "* [Configure job](#section2)\n",
    "* [Submit job](#section3)\n",
    "* [Delete job](#section4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a simple alias for Batch Shipyard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%alias shipyard SHIPYARD_CONFIGDIR=config python $HOME/batch-shipyard/shipyard.py %l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that everything is working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shipyard.py, version 2.8.0b1\r\n"
     ]
    }
   ],
   "source": [
    "shipyard --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get some variables stored in the Setup notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def read_json(filename):\n",
    "    with open(filename, 'r') as infile:\n",
    "        return json.load(infile)\n",
    "    \n",
    "account_info = read_json('account_information.json')\n",
    "\n",
    "IMAGE_NAME = account_info['IMAGE_NAME']\n",
    "STORAGE_ALIAS = account_info['STORAGE_ALIAS']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Configure job\n",
    "The following will be similar to the [Single GPU Training](02_Single_GPU_Training.ipynb) notebook from earlier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the `jobs` configuration, we will add `--logdir=tensorboard_logs` as a parameter to generate the Tensorboard summary log data during the run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TASK_ID = 'run_cifar10' # This should be changed per task\n",
    "\n",
    "JOB_ID = 'cntk-train-tensorboard-job'\n",
    "\n",
    "COMMAND = 'bash -c \"source /cntk/activate-cntk; python -u ConvNet_CIFAR10.py --datadir $AZ_BATCH_NODE_SHARED_DIR/data --tensorboard_logdir tensorboard_logs\"'\n",
    "\n",
    "jobs = {\n",
    "    \"job_specifications\": [\n",
    "        {\n",
    "            \"id\": JOB_ID,\n",
    "            \"tasks\": [\n",
    "                {\n",
    "                    \"id\": TASK_ID,\n",
    "                    \"image\": IMAGE_NAME,\n",
    "                    \"remove_container_after_exit\": True,\n",
    "                    \"command\": COMMAND,\n",
    "                    \"gpu\": True,\n",
    "                    \"resource_files\": [\n",
    "                        {\n",
    "                            \"file_path\": \"ConvNet_CIFAR10.py\",\n",
    "                            \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/ConvNet_CIFAR10.py\",\n",
    "                            \"file_mode\":'0777'\n",
    "                        }\n",
    "                    ],\n",
    "                    \"output_data\": {\n",
    "                        \"azure_storage\": [\n",
    "                            {\n",
    "                                \"storage_account_settings\": STORAGE_ALIAS,\n",
    "                                \"container\": \"output\",\n",
    "                                \"source\": \"$AZ_BATCH_TASK_WORKING_DIR/Models\"\n",
    "                            },\n",
    "                        ]\n",
    "                    },\n",
    "                }\n",
    "            ],\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Write the jobs configuration to the `jobs.json` file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"job_specifications\": [\n",
      "        {\n",
      "            \"id\": \"cntk-train-tensorboard-job\", \n",
      "            \"tasks\": [\n",
      "                {\n",
      "                    \"command\": \"bash -c \\\"source /cntk/activate-cntk; python -u ConvNet_CIFAR10.py --datadir $AZ_BATCH_NODE_SHARED_DIR/data --tensorboard_logdir tensorboard_logs\\\"\", \n",
      "                    \"gpu\": true, \n",
      "                    \"id\": \"run_cifar10\", \n",
      "                    \"image\": \"microsoft/cntk:2.0-gpu-python3.5-cuda8.0-cudnn5.1\", \n",
      "                    \"output_data\": {\n",
      "                        \"azure_storage\": [\n",
      "                            {\n",
      "                                \"container\": \"output\", \n",
      "                                \"source\": \"$AZ_BATCH_TASK_WORKING_DIR/Models\", \n",
      "                                \"storage_account_settings\": \"mystorageaccount\"\n",
      "                            }\n",
      "                        ]\n",
      "                    }, \n",
      "                    \"remove_container_after_exit\": true, \n",
      "                    \"resource_files\": [\n",
      "                        {\n",
      "                            \"blob_source\": \"https://batchshipyardexamples.blob.core.windows.net/code/ConvNet_CIFAR10.py\", \n",
      "                            \"file_mode\": \"0777\", \n",
      "                            \"file_path\": \"ConvNet_CIFAR10.py\"\n",
      "                        }\n",
      "                    ]\n",
      "                }\n",
      "            ]\n",
      "        }\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def write_json_to_file(json_dict, filename):\n",
    "    \"\"\" Simple function to write JSON dictionaries to files\n",
    "    \"\"\"\n",
    "    with open(filename, 'w') as outfile:\n",
    "        json.dump(json_dict, outfile)\n",
    "\n",
    "write_json_to_file(jobs, os.path.join('config', 'jobs.json'))\n",
    "print(json.dumps(jobs, indent=4, sort_keys=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit job\n",
    "Check that everything is ok with our pool before we submit our jobs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 10:22:30,267 DEBUG - listing nodes for pool gpupool\n",
      "2017-06-21 10:22:30,572 INFO - node_id=tvm-4283973576_1-20170621t092540z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.5 vm_size=standard_nc6 dedicated=True total_tasks_run=3 running_tasks_count=0 total_tasks_succeeded=3]\n",
      "2017-06-21 10:22:30,572 INFO - node_id=tvm-4283973576_2-20170621t092540z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.6 vm_size=standard_nc6 dedicated=True total_tasks_run=2 running_tasks_count=0 total_tasks_succeeded=2]\n",
      "2017-06-21 10:22:30,573 INFO - node_id=tvm-4283973576_3-20170621t092540z [state=ComputeNodeState.idle start_task_exit_code=0 scheduling_state=SchedulingState.enabled ip_address=10.0.0.4 vm_size=standard_nc6 dedicated=True total_tasks_run=4 running_tasks_count=0 total_tasks_succeeded=4]\n"
     ]
    }
   ],
   "source": [
    "shipyard pool listnodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have confirmed everything is working we can execute our job using the command below. Note that we'll not be using the `--tail` option so that the command completes and we can tunnel to Tensorboard concurrently as the task is executing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 10:22:33,811 INFO - Adding job cntk-train-tensorboard-job to pool gpupool\n",
      "2017-06-21 10:22:34,282 INFO - uploading file /tmp/tmpnI68Nv as u'shipyardtaskrf-cntk-train-tensorboard-job/run_cifar10.shipyard.envlist'\n",
      "2017-06-21 10:22:34,509 DEBUG - submitting 1 tasks (0 -> 0) to job cntk-train-tensorboard-job\n",
      "2017-06-21 10:22:34,715 INFO - submitted all 1 tasks to job cntk-train-tensorboard-job\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs add"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the Batch Shipyard command to instantiate a Tensorboard instance and create an SSH tunnel. The following cell should not return immediately if it is working. Browse to the Tensorboard URL output by the command (which will not be output in the notebook since it is a blocking call), which is http://localhost:6006/\n",
    "\n",
    "**Notes:**\n",
    "1. The Tensorboard instance may take some time to start since this pool does not have the TensorFlow Docker image pre-loaded.\n",
    "2. You will need to manually interrupt the kernel once you are done with your Tensorboard visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 10:22:38,618 INFO - job_id=cntk-train-tensorboard-job task_id=run_cifar10 [state=TaskState.running max_retries=0 retention_time=10675199 days, 2:48:05.477581 pool_id=gpupool node_id=tvm-4283973576_3-20170621t092540z start_time=2017-06-21 10:22:35.411588+00:00 end_time=None duration=n/a exit_code=None]\r\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs listtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 10:22:44,521 DEBUG - waiting for task run_cifar10 in job cntk-train-tensorboard-job to reach a valid state\n",
      "2017-06-21 10:22:44,740 DEBUG - using auto-detected logdir: tensorboard_logs\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/nbuser/batch-shipyard/shipyard.py\", line 1530, in <module>\n",
      "    cli()\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 722, in __call__\n",
      "    return self.main(*args, **kwargs)\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 697, in main\n",
      "    rv = self.invoke(ctx)\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 1066, in invoke\n",
      "    return _process_result(sub_ctx.command.invoke(sub_ctx))\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 895, in invoke\n",
      "    return ctx.invoke(self.callback, **ctx.params)\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 535, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/decorators.py\", line 64, in new_func\n",
      "    return ctx.invoke(f, obj, *args[1:], **kwargs)\n",
      "  File \"/home/nbuser/anaconda2_410/lib/python2.7/site-packages/click/core.py\", line 535, in invoke\n",
      "    return callback(*args, **kwargs)\n",
      "  File \"/home/nbuser/batch-shipyard/shipyard.py\", line 1525, in misc_tensorboard\n",
      "    ctx.batch_client, ctx.config, jobid, taskid, logdir, image)\n",
      "  File \"/home/nbuser/batch-shipyard/convoy/fleet.py\", line 2620, in action_misc_tensorboard\n",
      "    misc.tunnel_tensorboard(batch_client, config, jobid, taskid, logdir, image)\n",
      "  File \"/home/nbuser/batch-shipyard/convoy/misc.py\", line 124, in tunnel_tensorboard\n",
      "    config, pool.offer)) / 'batch' / 'tasks'\n",
      "AttributeError: 'PoolSettings' object has no attribute 'offer'\n"
     ]
    }
   ],
   "source": [
    "shipyard misc tensorboard --jobid $JOB_ID --taskid $TASK_ID -y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete the job use the command below. Just be aware that this will get rid of all the files created by the job and tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-06-21 10:22:58,491 INFO - Deleting job: cntk-train-tensorboard-job\n",
      "2017-06-21 10:22:58,492 DEBUG - disabling job cntk-train-tensorboard-job first due to task termination\n",
      "2017-06-21 10:22:59,305 INFO - Terminating task: run_cifar10\n",
      "Warning: Permanently added '[52.168.166.35]:50000' (ECDSA) to the list of known hosts.\n",
      "cntk-train-tensorboard-job-run_cifar10\n",
      "Connection to 52.168.166.35 closed.\n",
      "2017-06-21 10:23:01,328 DEBUG - waiting for task run_cifar10 in job cntk-train-tensorboard-job to terminate\n",
      "2017-06-21 10:23:01,736 DEBUG - waiting for job cntk-train-tensorboard-job to delete\n",
      "2017-06-21 10:23:33,330 INFO - job cntk-train-tensorboard-job does not exist\n"
     ]
    }
   ],
   "source": [
    "shipyard jobs del -y --termtasks --wait"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "You can proceed to the [Notebook: Clean Up](05_Clean_Up.ipynb) if you are done for now, or proceed to one of the following additional Notebooks:\n",
    "* [Notebook: Automatic Model Selection](06_Advanced_Auto_Model_Selection.ipynb)\n",
    "* [Notebook: Parallel and Distributed](08_Advanced_Parallel_and_Distributed.ipynb)\n",
    "* [Notebook: Keras with TensorFlow](09_Keras_Single_GPU_Training_With_Tensorflow.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}